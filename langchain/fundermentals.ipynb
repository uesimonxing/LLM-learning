{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import iplantuml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BasePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数学模型**\n",
    "$$\n",
    "R_{BasePromptTemplate} = Dict \\times PromptValue\n",
    "$$\n",
    "**代码模型**\n",
    "```python\n",
    "class BasePromptTemplate(Serializable, Runnable[Dict, PromptValue], ABC):\n",
    "    # ------ Initializer Parameters ------\n",
    "    input_variables: List[str]\n",
    "    output_parser: Optional[BaseOutputParser] = None\n",
    "    partial_variables: Mapping[str, Union[str, Callable[[], str]]]\n",
    "\n",
    "\n",
    "    # ------ localized version invoke ------\n",
    "    @abstractmethod\n",
    "    def format_prompt(self, **kwargs: Any) -> PromptValue:\n",
    "        \"\"\"Create Chat Messages.\"\"\"\n",
    "    @abstractmethod\n",
    "    def format(self, **kwargs: Any) -> str:\n",
    "        \"\"\"Format the prompt with the inputs.\n",
    "\n",
    "        Args:\n",
    "            kwargs: Any arguments to be passed to the prompt template.\n",
    "\n",
    "        Returns:\n",
    "            A formatted string.\n",
    "\n",
    "        Example:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            prompt.format(variable1=\"foo\")\n",
    "        \"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StringPromptTemplate\n",
    "**代码模型**\n",
    "```python\n",
    "    class StringPromptTemplate(BasePromptTemplate, ABC):\n",
    "        \"\"\"String prompt that exposes the format method, returning a prompt.\"\"\"\n",
    "\n",
    "        # localized version invoke\n",
    "        def format_prompt(self, **kwargs: Any) -> PromptValue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate\n",
    "***数学模型***\n",
    "$$\n",
    "R_{PromptTemplate} = Dict \\times PromptValue \\\\\n",
    "\n",
    "    Dict = {input\\_variables:List[str], template:str, template\\_format: str, validate\\_template: bool} \\\\\n",
    "$$\n",
    "新增运算 $r_x + r_y = r_z$\n",
    "\n",
    "***代码模型***\n",
    "```python\n",
    "    @final.langchain\n",
    "    class PromptTemplate(StringPromptTemplate):\n",
    "        # ------ Initializer Parameters ------\n",
    "        input_variables: List[str]\n",
    "        \"\"\"A list of the names of the variables the prompt template expects.\"\"\"\n",
    "        template: str\n",
    "        \"\"\"The prompt template.\"\"\"\n",
    "        template_format: str = \"f-string\"\n",
    "        \"\"\"The format of the prompt template. Options are: 'f-string', 'jinja2'.\"\"\"\n",
    "        validate_template: bool = True\n",
    "        \"\"\"Whether or not to try validating the template.\"\"\"\n",
    "\n",
    "        # ------ operators ------\n",
    "        def __add__(self, other: Any) -> PromptTemplate:\n",
    "\n",
    "        # ------ localized version invoke ------\n",
    "        def format_prompt(self, **kwargs: Any) -> PromptValue:\n",
    "        def format(self, **kwargs: Any) -> str:\n",
    "\n",
    "        # ------- factory methods ------\n",
    "        @classmethod\n",
    "        def from_examples(...) -> PromptTemplate:\n",
    "        @classmethod\n",
    "        def from_file(...) -> PromptTemplate:\n",
    "        @classmethod\n",
    "        def from_template(...) -> PromptTemplate:\n",
    "```\n",
    "***示例代码***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['foo'] output_parser=None partial_variables={} template='tell me a joke about {foo}' template_format='f-string' validate_template=True\n",
      "tell me a joke about bear\n",
      "input_variables=['foo'] output_parser=None partial_variables={} template='tell me a joke about {foo}' template_format='f-string' validate_template=True\n",
      "tell me a joke about bear\n",
      "input_variables=['foo'] output_parser=None partial_variables={} template='tell me a joke about {foo}' template_format='f-string' validate_template=True\n",
      "tell me a joke about bear\n",
      "input_variables=['foo'] output_parser=None partial_variables={} template='tell me a joke about {foo}' template_format='f-string' validate_template=True\n",
      "Runnable.output[PromptValue]=text='tell me a joke about bear'\n",
      "input_variables=['foo'] output_parser=None partial_variables={} template='tell me a joke about {foo}' template_format='f-string' validate_template=True\n",
      "BasePromptTemplate.output.str=tell me a joke about bear\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "def BasePromptTemplate_initializer_version():\n",
    "    initializer_input = {\n",
    "        'input_variables': ['foo'],\n",
    "        'output_parser': None,\n",
    "        'partial_variables': {},\n",
    "        'template': 'tell me a joke about {foo}',\n",
    "        'template_format': 'f-string',\n",
    "        'validate_template': True\n",
    "    }\n",
    "    r = PromptTemplate(**initializer_input)\n",
    "    print(r)\n",
    "    return r\n",
    "\n",
    "def PromptTemplate_initializer_version():\n",
    "    initializer_input = {\n",
    "        'input_variables': ['foo'],\n",
    "        'template': 'tell me a joke about {foo}',\n",
    "    }\n",
    "    r = PromptTemplate(**initializer_input)\n",
    "    print(r)\n",
    "    return r\n",
    "\n",
    "def PromptTemplate_factory_version():\n",
    "    r = PromptTemplate.from_template(template='tell me a joke about {foo}')\n",
    "    print(r)\n",
    "    return r\n",
    "\n",
    "\n",
    "factories = [\n",
    "    BasePromptTemplate_initializer_version,\n",
    "    PromptTemplate_initializer_version,\n",
    "    PromptTemplate_factory_version\n",
    "]\n",
    "\n",
    "for factory in factories:\n",
    "    runnable = factory()\n",
    "    output = runnable.format(foo='bear')\n",
    "    print(output)\n",
    "\n",
    "def Runnable_invoke_to_PromptValue(factory):\n",
    "    runnable = factory()\n",
    "\n",
    "    input: Dict = {'foo': 'bear'}\n",
    "    output = runnable.invoke(input=input) # -> PromptValue\n",
    "\n",
    "    print(f'Runnable.output[PromptValue]={output}')\n",
    "\n",
    "def BasePromptTemplate_invoke_format_to_str(factory):\n",
    "    runnable = factory()\n",
    "\n",
    "    output = runnable.format(foo='bear') # -> str\n",
    "\n",
    "    print(f'BasePromptTemplate.output.str={output}')\n",
    "\n",
    "import random\n",
    "factory = random.choice(factories)\n",
    "Runnable_invoke_to_PromptValue(factory)\n",
    "BasePromptTemplate_invoke_format_to_str(factory)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me a cool name for my red car.write a short poem about my red car.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableSequence\n",
    "\n",
    "rx = PromptTemplate.from_template(template='give me a cool name for my {color} {thing}.')\n",
    "ry = PromptTemplate.from_template(template='write a short {format} about my {color} {thing}.')\n",
    "\n",
    "r_plus = rx + ry\n",
    "print(r_plus.format(color='red', thing='car', format='poem'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaseChatPromptTemplate\n",
    "**代码模型**\n",
    "```python\n",
    "    class BaseChatPromptTemplate(BasePromptTemplate, ABC):\n",
    "        \"\"\"Base class for chat prompt templates.\"\"\"\n",
    "\n",
    "        # override's the super version\n",
    "        def format_prompt(self, **kwargs: Any) -> PromptValue:\n",
    "        def format(self, **kwargs: Any) -> str:\n",
    "\n",
    "        # localized version invoke\n",
    "        @abstractmethod\n",
    "        def format_messages(self, **kwargs: Any) -> List[BaseMessage]:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatPromptTemplate\n",
    "**代码模型**\n",
    "```python\n",
    "    class ChatPromptTemplate(BaseChatPromptTemplate, ABC):\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['foo'] output_parser=None partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['foo'], output_parser=None, partial_variables={}, template='tell me a joke about {foo}', template_format='f-string', validate_template=True), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import *\n",
    "from langchain.prompts.chat import BaseMessagePromptTemplate\n",
    "\n",
    "message_prompt_template: BaseMessagePromptTemplate = HumanMessagePromptTemplate.from_template('tell me a joke about {foo}')\n",
    "# runnable = ChatPromptTemplate().from_messages(messages=[message_prompt_template])\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {foo}\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseGenerationOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseLanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-learning-jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
